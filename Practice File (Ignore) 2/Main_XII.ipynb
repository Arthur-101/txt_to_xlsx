{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openpyxl import Workbook\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import Alignment\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files :-\n",
    "open_file_from = '65027 XII.txt'\n",
    "save_file_at = 'Output_Excel_2.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the text file:-\n",
    "with open(open_file_from) as file:\n",
    "    reader = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the patterns to get 'Date', 'School Code', 'School Name' and Region' :-\n",
    "date_pattern = r\"DATE:- (\\d{2}/\\d{2}/\\d{4})\"\n",
    "school_pattern = r\"SCHOOL : - (\\d+) (.+)\"\n",
    "region_pattern = r\"REGION:\\s+(\\S+)\"\n",
    "\n",
    "# Finding the matches for 'Date', 'School code', 'School name', and 'Region' :-\n",
    "date_match = re.search(date_pattern, reader)\n",
    "school_match = re.search(school_pattern, reader)\n",
    "region_match = re.search(region_pattern, reader)\n",
    "\n",
    "# Giving variable name to all the data:-\n",
    "date = date_match.group(1) if date_match else \"\"\n",
    "school_code = school_match.group(1) if school_match else \"\"\n",
    "school_name = school_match.group(2) if school_match else \"\"\n",
    "region = region_match.group(1) if region_match else \"\"\n",
    "\n",
    "# Defining the patterns to get all the outro information :-\n",
    "total_candidates_pattern = r\"TOTAL CANDIDATES\\s*:\\s*(\\d+)\"\n",
    "total_pass_pattern = r\"TOTAL PASS\\s*:\\s*(\\d+)\"\n",
    "total_comptt_pattern = r\"TOTAL COMPTT\\.\\s*:\\s*(\\d+)\"\n",
    "total_essential_repeat_pattern = r\"TOTAL ESSENTIAL REPEAT\\s*:\\s*(\\d+)\"\n",
    "total_absent_pattern = r\"TOTAL ABSENT\\s*:\\s*(\\d+)\"\n",
    "\n",
    "# Finding the matches of above defined pattern in the file:-\n",
    "total_candidates_match = re.search(total_candidates_pattern, reader)\n",
    "total_pass_match = re.search(total_pass_pattern, reader)\n",
    "total_comptt_match = re.search(total_comptt_pattern, reader)\n",
    "total_essential_repeat_match = re.search(total_essential_repeat_pattern, reader)\n",
    "total_absent_match = re.search(total_absent_pattern, reader)\n",
    "\n",
    "# Giving variable names to all the data :-\n",
    "total_candidates = total_candidates_match.group(1) if total_candidates_match else \"\"\n",
    "total_pass = total_pass_match.group(1) if total_pass_match else \"\"\n",
    "total_comptt = total_comptt_match.group(1) if total_comptt_match else \"\"\n",
    "total_essential_repeat = total_essential_repeat_match.group(1) if total_essential_repeat_match else \"\"\n",
    "total_absent = total_absent_match.group(1) if total_absent_match else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pattern to match the unwanted text (from the top of the string to the line starting with \"SCHOOL\")\n",
    "unwanted_pattern = r'DATE:.*?\\n.*?-----.*?\\n\\nSCHOOL.*?\\n'\n",
    "\n",
    "# Remove unwanted text using re.sub\n",
    "input_string_cleaned = re.sub(unwanted_pattern, '', reader, flags=re.DOTALL)\n",
    "\n",
    "# Pattern to extract Roll, Gender, and Name\n",
    "roll_gender_name_pattern = r\"(\\d+)\\s+(\\w)\\s+([A-Z ]+)\"\n",
    "\n",
    "# Pattern to extract Subject Codes\n",
    "subject_codes_pattern = r\"(\\d{3}\\s+){5}(\\d{3})?\"\n",
    "\n",
    "# Pattern to extract Result\n",
    "result_pattern = r\"\\b(PASS|FAIL|COMP|ABST)\\b\"\n",
    "\n",
    "# Pattern to extract Marks and Grades for each subject\n",
    "marks_grades_pattern = r\"(\\d{3}|AB)\\s+([A-Z]\\d?)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing an empty list to store each student's data as a dictionary\n",
    "students_data = []\n",
    "\n",
    "# Initializing variables to keep track of student information\n",
    "current_student_info = None\n",
    "current_student_grades = None\n",
    "\n",
    "# Spliting the input_string by newline characters\n",
    "lines = reader.strip().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a Function to process and add student data to students_data list\n",
    "def add_student_data(roll, gender, name, subject_codes, result, marks_grades):\n",
    "    marks = []\n",
    "    grades = []\n",
    "    for mark_grade_tuple in marks_grades:\n",
    "        mark, grade = mark_grade_tuple[0], mark_grade_tuple[1]\n",
    "        if mark.isdigit():\n",
    "            marks.append(int(mark))\n",
    "        else:\n",
    "            marks.append(mark)\n",
    "        grades.append(grade)\n",
    "\n",
    "    if len(subject_codes) < 6 and len(marks) < 6 and len(grades) < 6:\n",
    "        subject_codes.append(np.NaN)\n",
    "        marks.append(np.NaN)\n",
    "        grades.append(np.NaN)\n",
    "\n",
    "    row_data = {\n",
    "        'Roll': roll,\n",
    "        'Gender': gender,\n",
    "        'Name': name.strip(),\n",
    "        'Sub_1': subject_codes[0],\n",
    "        'Marks_1': marks[0],\n",
    "        'grade_1': grades[0],\n",
    "        'Sub_2': subject_codes[1],\n",
    "        'Marks_2': marks[1],\n",
    "        'grade_2': grades[1],\n",
    "        'Sub_3': subject_codes[2],\n",
    "        'Marks_3': marks[2],\n",
    "        'grade_3': grades[2],\n",
    "        'Sub_4': subject_codes[3],\n",
    "        'Marks_4': marks[3],\n",
    "        'grade_4': grades[3],\n",
    "        'Sub_5': subject_codes[4],\n",
    "        'Marks_5': marks[4],\n",
    "        'grade_5': grades[4],\n",
    "        'Sub_6': subject_codes[5],\n",
    "        'Marks_6': marks[5],\n",
    "        'grade_6': grades[5],\n",
    "        'Result': result\n",
    "    }\n",
    "    \n",
    "    students_data.append(row_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterating through each line to process student data\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    # Checking if the line contains Roll, Gender, and Name\n",
    "    if re.match(roll_gender_name_pattern, line):\n",
    "        current_student_info = line\n",
    "    # Checking if the line contains Marks and Grades\n",
    "    elif re.match(marks_grades_pattern, line):\n",
    "        current_student_grades = line\n",
    "        # Extracting Roll, Gender, and Name\n",
    "        roll, gender, name = re.search(roll_gender_name_pattern, current_student_info).groups()\n",
    "\n",
    "        # Extracting Subject Codes and Separating individual subject codes\n",
    "        subject_codes_string = re.search(subject_codes_pattern, current_student_info).group()\n",
    "        subject_codes = re.findall(r\"\\d{3}\", subject_codes_string)\n",
    "\n",
    "        # Extracting Result\n",
    "        result = re.search(result_pattern, current_student_info).group()\n",
    "\n",
    "        # Extracting Marks and Grades for each subject\n",
    "        marks_grades = re.findall(marks_grades_pattern, current_student_grades)\n",
    "\n",
    "        # Adding student data to students_data list\n",
    "        add_student_data(roll, gender, name, subject_codes, result, marks_grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the final DataFrame using the list of student dictionaries\n",
    "df = pd.DataFrame(students_data)\n",
    "\n",
    "# Reseting the index of the DataFrame\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df = df.fillna(\"\")\n",
    "\n",
    "# Printing the DataFrame\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract numeric value from a string\n",
    "def extract_numeric(value):\n",
    "    numeric_part = re.sub(r'\\D', '', str(value))\n",
    "    return int(numeric_part) if numeric_part.isdigit() else 0\n",
    "\n",
    "# Apply the function to extract numeric values from Marks columns\n",
    "df['Marks_1'] = df['Marks_1'].apply(extract_numeric)\n",
    "df['Marks_2'] = df['Marks_2'].apply(extract_numeric)\n",
    "df['Marks_3'] = df['Marks_3'].apply(extract_numeric)\n",
    "df['Marks_4'] = df['Marks_4'].apply(extract_numeric)\n",
    "df['Marks_5'] = df['Marks_5'].apply(extract_numeric)\n",
    "df['Marks_6'] = df['Marks_6'].apply(extract_numeric)\n",
    "\n",
    "# Add a new column 'Total_Marks'\n",
    "df['Total_Marks'] = df['Marks_1'] + df['Marks_2'] + df['Marks_3'] + df['Marks_4'] + df['Marks_5'] + df['Marks_6']\n",
    "\n",
    "# Calculating and Summing Up the best five marks for each row and adding a new column 'Total Marks (Best 5)'\n",
    "df['Total Marks (Best 5)'] = df[['Marks_1', 'Marks_2', 'Marks_3', 'Marks_4', 'Marks_5', 'Marks_6']].apply(lambda row: sum(sorted(row, reverse=True)[:5]), axis=1)\n",
    "\n",
    "# Calculate percentage and add a new column 'Percentage (%)'\n",
    "total_possible_marks = 500\n",
    "df['Percentage (%)'] = (df['Total Marks (Best 5)'] / total_possible_marks) * 100\n",
    "df['Percentage (%)'] = df['Percentage (%)'].apply(lambda x: round(x, 2))\n",
    "\n",
    "# Printing the DataFrame\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique subject codes\n",
    "subject_codes = df[['Sub_1', 'Sub_2', 'Sub_3', 'Sub_4', 'Sub_5', 'Sub_6']].values.flatten()\n",
    "subject_codes = np.unique(subject_codes)\n",
    "\n",
    "# Create a new dataframe\n",
    "new_columns = ['Roll', 'Gender', 'Name']\n",
    "for code in subject_codes:\n",
    "    new_columns.append(code)\n",
    "    new_columns.append('Grade_' + code)\n",
    "new_columns.append('Total Marks')                # Add a new column 'Total_Marks'\n",
    "new_columns.append('Total Marks (Best 5)')         # Add a new column 'Total_Marks (Best 5)'\n",
    "\n",
    "new_df = pd.DataFrame(columns=new_columns)\n",
    "\n",
    "# Iterate through rows and populate the new dataframe\n",
    "for _, row in df.iterrows():\n",
    "    new_row = [row['Roll'], row['Gender'], row['Name']]\n",
    "    total_marks = 0\n",
    "    best_marks = []\n",
    "    for code in subject_codes:\n",
    "        matching_index = np.where(row[['Sub_1', 'Sub_2', 'Sub_3', 'Sub_4', 'Sub_5', 'Sub_6']] == code)[0]\n",
    "        if matching_index.size > 0:\n",
    "            marks = row['Marks_' + str(matching_index[0] + 1)]\n",
    "            grade = row['grade_' + str(matching_index[0] + 1)]\n",
    "            total_marks += marks           # Adding total marks in a list\n",
    "            best_marks.append(marks)       # Adding total marks (Best 5) in a list\n",
    "            new_row.append(marks)\n",
    "            new_row.append(grade)\n",
    "        else:\n",
    "            new_row.append(np.NaN)\n",
    "            new_row.append(np.NaN)\n",
    "\n",
    "    # Adding all `Total_Marks` and `Total_Marks (Best 5)` in new columns\n",
    "    best_marks.sort(reverse=True)\n",
    "    total_marks_best_5 = sum(best_marks[:5])\n",
    "    new_row.append(total_marks)\n",
    "    new_row.append(total_marks_best_5)\n",
    "\n",
    "    new_df.loc[len(new_df)] = new_row\n",
    "\n",
    "# Calculate percentage and add a new column 'Percentage (%)'\n",
    "total_possible_marks = 500\n",
    "new_df['Percentage (%)'] = (new_df['Total Marks (Best 5)'] / total_possible_marks) * 100\n",
    "new_df['Percentage (%)'] = new_df['Percentage (%)'].apply(lambda x: round(x, 2))\n",
    "\n",
    "new_df = new_df.fillna('')\n",
    "\n",
    "# Iterate through columns in the DataFrame to check for empty columns and remove it\n",
    "for col in new_df.columns:\n",
    "    if all(new_df[col] == \"\"):\n",
    "        new_df.drop(columns=[col], inplace=True)\n",
    "\n",
    "# Remove columns with empty string as name\n",
    "columns_to_remove = [col for col in new_df.columns if col == \"\"]\n",
    "new_df.drop(columns=columns_to_remove, inplace=True)\n",
    "\n",
    "# Printing the new_df\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an Excel Workbook\n",
    "workbook = Workbook()\n",
    "sheet = workbook.active\n",
    "sheet.title = 'Result'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding additional information (Date, School Code, School Name, Region) to the Excel file\n",
    "sheet['A1'] = 'Date:-'\n",
    "sheet['A2'] = 'School Code'\n",
    "sheet['H1'] = 'Region:'\n",
    "\n",
    "sheet['B1'] = date\n",
    "sheet['B2'] = school_code\n",
    "sheet['I1'] = region\n",
    "\n",
    "start_column = 'C'\n",
    "end_column = 'G'\n",
    "merged_cell = sheet[start_column + '3']\n",
    "merged_cell.alignment = Alignment(horizontal='center', vertical='center')\n",
    "sheet.merge_cells(f'{start_column}3:{end_column}3')           # Merging cells for the school_name\n",
    "sheet[f'{start_column}3'] = school_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing DataFrame rows to Excel, starting from the specified row\n",
    "for row in dataframe_to_rows(new_df, index=False, header=True, ):\n",
    "    sheet.append(row)\n",
    "sheet.append([' '])\n",
    "\n",
    "start_row = 4\n",
    "\n",
    "# Adding Outro Information :-\n",
    "end = sheet.max_row\n",
    "sheet['A'+str(end+2)] = 'Total Candidates :- '\n",
    "sheet['D'+str(end+2)] = 'Total Absent :- '\n",
    "sheet['A'+str(end+3)] = 'Total Pass :- '\n",
    "sheet['D'+str(end+3)] = 'Total Comptt. :-'\n",
    "sheet['A'+str(end+4)] = 'Total Essential Repeat :- '\n",
    "\n",
    "sheet['B'+str(end+2)] = total_candidates\n",
    "sheet['E'+str(end+2)] = total_absent\n",
    "sheet['B'+str(end+3)] = total_pass\n",
    "sheet['E'+str(end+3)] = total_comptt\n",
    "sheet['B'+str(end+4)] = total_essential_repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the Excel file\n",
    "workbook.save(save_file_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty dataframes to store rows\n",
    "science_df = pd.DataFrame(columns= new_df.columns)\n",
    "commerce_df = pd.DataFrame(columns= new_df.columns)\n",
    "pcm_df = pd.DataFrame(columns=new_df.columns)\n",
    "pcb_df = pd.DataFrame(columns=new_df.columns)\n",
    "\n",
    "# Iterate through rows\n",
    "for index, row in new_df.iterrows():\n",
    "    if row['042'] != '':\n",
    "        science_df = pd.concat([science_df, pd.DataFrame([row])], ignore_index=True)\n",
    "\n",
    "        if row['041'] != '':       # DataFrame for PCM stream\n",
    "            pcm_df = pd.concat([pcm_df, pd.DataFrame([row])], ignore_index=True)\n",
    "        elif row['044'] != '':       # DataFrame for PCB stream\n",
    "            pcb_df = pd.concat([pcb_df, pd.DataFrame([row])], ignore_index=True)\n",
    "\n",
    "    elif row['030'] != '' or row['054'] != '' or row['055'] != '':\n",
    "        commerce_df = pd.concat([commerce_df, pd.DataFrame([row])], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refining the columns one last time\n",
    "for col in science_df.columns:\n",
    "    if all(science_df[col] == \"\"):\n",
    "        science_df.drop(columns=[col], inplace=True)\n",
    "\n",
    "for col in commerce_df.columns:\n",
    "    if all(commerce_df[col] == \"\"):\n",
    "        commerce_df.drop(columns=[col], inplace=True)\n",
    "\n",
    "for col in pcm_df.columns:\n",
    "    if all(pcm_df[col] == \"\"):\n",
    "        pcm_df.drop(columns=[col], inplace=True)\n",
    "for col in pcb_df.columns:\n",
    "    if all(pcb_df[col] == \"\"):\n",
    "        pcb_df.drop(columns=[col], inplace=True)\n",
    "\n",
    "# Acessing all the data to find QPI\n",
    "sum_science = science_df['Total Marks (Best 5)'].sum()\n",
    "len_science = len(science_df)\n",
    "sum_commerce = commerce_df['Total Marks (Best 5)'].sum()\n",
    "len_commerce = len(commerce_df)\n",
    "t_sub = 5\n",
    "\n",
    "# Finding QPI of PCM, PCB and Commerce :\n",
    "qpi_science = (sum_science / (len_science * t_sub)) \n",
    "qpi_commerce = (sum_commerce /  (len_commerce * t_sub))\n",
    "\n",
    "print(qpi_science)\n",
    "print(qpi_commerce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "science_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commerce_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the Excel file to add new sheets and data\n",
    "with pd.ExcelWriter(save_file_at, engine='openpyxl', mode='a') as writer:\n",
    "    science_df.to_excel(writer, sheet_name='Science', index=False)\n",
    "    pcm_df.to_excel(writer, sheet_name='Maths', index=False)\n",
    "    pcb_df.to_excel(writer, sheet_name='Biology', index=False)\n",
    "    commerce_df.to_excel(writer, sheet_name='Commerce', index=False)\n",
    "\n",
    "# Adding QPI in the Sheets :\n",
    "workbook = load_workbook(save_file_at)\n",
    "sheet_science = workbook['Science']     # For Science\n",
    "end = sheet_science.max_row\n",
    "sheet_science['A'+str(end+2)] = 'QPI : '\n",
    "sheet_science['B'+str(end+2)] = qpi_science\n",
    "workbook.save(save_file_at)\n",
    "\n",
    "workbook = load_workbook(save_file_at)\n",
    "sheet_commerce = workbook['Commerce']           # For Commerce\n",
    "end = sheet_commerce.max_row\n",
    "sheet_commerce['A'+str(end+2)] = 'QPI : '\n",
    "sheet_commerce['B'+str(end+2)] = qpi_commerce\n",
    "workbook.save(save_file_at)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the number of students Percentage wise :\n",
    "count_above_90 = len(new_df[new_df['Percentage (%)'] >= 90])\n",
    "count_between_80_and_89 = len(new_df[(new_df['Percentage (%)'] >= 80) & (new_df['Percentage (%)'] <= 89)])\n",
    "count_between_75_and_79 = len(new_df[(new_df['Percentage (%)'] >= 75) & (new_df['Percentage (%)'] <= 79)])\n",
    "count_between_60_and_74 = len(new_df[(new_df['Percentage (%)'] >= 60) & (new_df['Percentage (%)'] <= 74)])\n",
    "count_below_60 = len(new_df[new_df['Percentage (%)'] < 60])\n",
    "\n",
    "# Creating a dataframe for Percentage count : \n",
    "count_data = {'Percentage' : ['Above 90%', '80% to 89%', '75% to 79%', '60% to 74%', 'Below 60%'],\n",
    "    'Total No of student' : [count_above_90, count_between_80_and_89, count_between_75_and_79, \n",
    "                                       count_between_60_and_74, count_below_60]}\n",
    "\n",
    "percentage_count_df = pd.DataFrame(count_data)\n",
    "\n",
    "percentage_count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the number of Students Subject wise : \n",
    "Subject_percentage_count_df = pd.DataFrame({'Sr. No.':[1,2,3,4,5,6,7,8,9,10,11,12],\n",
    "    'Subject Name':['Maths', 'Physics', 'Chemistry', 'Biology', 'English', 'Physical Education', 'Economics',\n",
    "                    'Business Studies', 'Accountancy', 'Hindi', 'Sanskrit', 'I.P.']})\n",
    "\n",
    "sub_codes = ['041','042','043','044','301','048','030','054','055','302','322','065']\n",
    "\n",
    "#Empty lists to make columns\n",
    "above_90 = []\n",
    "between_80_89 = []\n",
    "between_70_79 = []\n",
    "between_60_69 = []\n",
    "below_60 = []\n",
    "\n",
    "# Iteration through every subject columns : \n",
    "for s_code in sub_codes:\n",
    "    # Filter out empty strings before conversion\n",
    "    non_empty_values = new_df[s_code][new_df[s_code] != '']\n",
    "    non_empty_values = non_empty_values.astype(int, errors='ignore')\n",
    "    \n",
    "    count_above_90 = len(non_empty_values[non_empty_values >= 90])\n",
    "    above_90.append(count_above_90)\n",
    "    \n",
    "    count_between_80_and_89 = len(non_empty_values[(non_empty_values >= 80) & (non_empty_values <= 89)])\n",
    "    between_80_89.append(count_between_80_and_89)\n",
    "    \n",
    "    count_between_70_and_79 = len(non_empty_values[(non_empty_values >= 70) & (non_empty_values <= 79)])\n",
    "    between_70_79.append(count_between_70_and_79)\n",
    "    \n",
    "    count_between_60_and_69 = len(non_empty_values[(non_empty_values >= 60) & (non_empty_values <= 69)])\n",
    "    between_60_69.append(count_between_60_and_69)\n",
    "    \n",
    "    count_below_60 = len(non_empty_values[non_empty_values < 60])\n",
    "    below_60.append(count_below_60)\n",
    "\n",
    "Subject_percentage_count_df['90% and Above'] = above_90\n",
    "Subject_percentage_count_df['80% To 89%'] = between_80_89\n",
    "Subject_percentage_count_df['70% To 79%'] = between_70_79\n",
    "Subject_percentage_count_df['60% To 69%'] = between_60_69\n",
    "Subject_percentage_count_df['Below 60%'] = below_60\n",
    "\n",
    "# Adding Total Students in a new column :\n",
    "Subject_percentage_count_df['Total Student'] = Subject_percentage_count_df.iloc[:, 2:].sum(axis=1)\n",
    "\n",
    "Subject_percentage_count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_marks_df = pd.DataFrame({'Sr. No.':[1,2,3,4,5,6,7,8,9,10,11,12],\n",
    "    'Subject Codes':['041','042','043','044','301','048','030','054','055','302','322','065'],\n",
    "    'Subject Name':['Maths', 'Physics', 'Chemistry', 'Biology', 'English', 'Physical Education', 'Economics',\n",
    "                    'Business Studies', 'Accountancy', 'Hindi', 'Sanskrit', 'I.P.']})\n",
    "\n",
    "sub_codes = ['041','042','043','044','301','048','030','054','055','302','322','065']\n",
    "\n",
    "# Create an empty list to store dictionaries of highest marks information\n",
    "highest_marks_data = []\n",
    "\n",
    "# Iterate through each subject\n",
    "for s_code in sub_codes:\n",
    "    # Convert the column to numeric (ignoring errors)\n",
    "    new_df[s_code] = pd.to_numeric(new_df[s_code], errors='coerce')\n",
    "\n",
    "    # Find the highest marks and the corresponding students' names\n",
    "    highest_marks = new_df[s_code].max()\n",
    "    highest_mark_students = new_df[new_df[s_code] == highest_marks]['Name'].tolist()\n",
    "    highest_mark_students = ', '.join(highest_mark_students)  # Join names into a string and remove from list\n",
    "\n",
    "    # Update the corresponding rows in the existing dataframe\n",
    "    highest_marks_df.loc[highest_marks_df['Subject Codes'] == s_code, 'Highest Marks'] = highest_marks\n",
    "    highest_marks_df.loc[highest_marks_df['Subject Codes'] == s_code, 'Name of Toppers'] = highest_mark_students\n",
    "\n",
    "highest_marks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the existing Excel file\n",
    "workbook = load_workbook(filename=save_file_at)\n",
    "# Create a new sheet\n",
    "sheet = workbook.create_sheet(title='Analysis')\n",
    "sheet = workbook['Analysis']\n",
    "sheet2 = workbook.create_sheet(title='Analysis 2')\n",
    "sheet2 = workbook['Analysis 2']\n",
    "\n",
    "# Writing DataFrame rows to Excel, starting from the specified row\n",
    "for row in dataframe_to_rows(percentage_count_df, index=False, header=True):\n",
    "    sheet.append(row)\n",
    "sheet.append([' '])\n",
    "\n",
    "for row in dataframe_to_rows(Subject_percentage_count_df, index=False, header=True, ):\n",
    "    sheet.append(row)\n",
    "sheet.append([' '])\n",
    "\n",
    "for row in dataframe_to_rows(highest_marks_df, index=False, header=True, ):\n",
    "    sheet.append(row)\n",
    "sheet.append([' '])\n",
    "\n",
    "for row in dataframe_to_rows(highest_marks_df, index=False, header=True, ):\n",
    "    sheet2.append(row)\n",
    "sheet2.append([' '])\n",
    "\n",
    "# Saving the Excel file\n",
    "workbook.save(save_file_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
